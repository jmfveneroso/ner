{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "from models.estimator import Estimator\n",
    "from models.hmm import HiddenMarkov, load_raw_dataset\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Disable debug logs Tensorflow.\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-LSTM-CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model...\n",
      "Loss: 0.1675, Acc: 1.0000, Time: 3.2803, Step: 300\n",
      "Loss: 0.1649, Acc: 1.0000, Time: 4.8178, Step: 600\n",
      "Loss: 0.0199, Acc: 1.0000, Time: 6.3680, Step: 900\n",
      "Loss: 0.0026, Acc: 1.0000, Time: 8.3494, Step: 1200\n",
      "Loss: 0.1104, Acc: 1.0000, Time: 9.8134, Step: 1500\n",
      "Loss: 0.0226, Acc: 1.0000, Time: 11.4722, Step: 1800\n",
      "Loss: 0.1084, Acc: 1.0000, Time: 13.0408, Step: 2100\n",
      "Loss: 0.0482, Acc: 1.0000, Time: 14.5014, Step: 2400\n",
      "Loss: 0.1039, Acc: 1.0000, Time: 14.9431, Step: 2474\n",
      "train - Epoch 0, Precision: 0.7887, Recall: 0.7595, F1: 0.7738\n",
      "Loss: 0.3397, Acc: 0.9692, Time: 2.1385, Step: 300\n",
      "Loss: 0.2148, Acc: 0.9800, Time: 3.7365, Step: 600\n",
      "Loss: 0.0018, Acc: 1.0000, Time: 5.0893, Step: 876\n",
      "valid - Epoch 0, Precision: 0.7718, Recall: 0.7981, F1: 0.7847\n",
      "Loss: 1.0599, Acc: 0.9667, Time: 2.3508, Step: 300\n",
      "Loss: 0.0883, Acc: 1.0000, Time: 4.1859, Step: 600\n",
      "Loss: 0.7030, Acc: 0.9733, Time: 5.9270, Step: 900\n",
      "Loss: 0.1643, Acc: 1.0000, Time: 6.6686, Step: 1041\n",
      "test - Epoch 0, Precision: 0.7999, Recall: 0.6710, F1: 0.7298\n"
     ]
    }
   ],
   "source": [
    "# estimator = Estimator(model, )\n",
    "estimator = Estimator()\n",
    "estimator.set_dataset_params({\n",
    "  'model': 'crf', # crf, lstm_crf, html_attention, self_attention\n",
    "  # 'lstm_size': 200,\n",
    "  # 'decoder': 'crf', # crf, logits.\n",
    "  # 'char_representation': 'cnn',\n",
    "  # 'word_embeddings': 'glove', # glove, elmo. TODO: bert.\n",
    "  # 'use_features': False, \n",
    "  # 'f_score_alpha': 0.5,\n",
    "})\n",
    "# estimator.train()\n",
    "estimator.test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.1350e+04 1.0000e+00 5.8230e+03]\n",
      " [1.0000e+00 1.0000e+00 1.0000e+00]\n",
      " [3.0240e+03 1.0000e+00 1.0076e+04]]\n",
      "[[9.40066273e-01 1.02908185e-05 5.99234363e-02]\n",
      " [3.33333333e-01 3.33333333e-01 3.33333333e-01]\n",
      " [2.30822075e-01 7.63300511e-05 7.69101595e-01]]\n",
      "Predicting train\n",
      "Predicting valid\n",
      "Predicting test\n",
      "Elapsed time: 27.2895\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "timesteps = 1\n",
    "naive_bayes = timesteps == 0\n",
    "if naive_bayes:\n",
    "    timesteps = 1\n",
    "    \n",
    "X, Y, _ = load_raw_dataset('data/train')\n",
    "hmm = HiddenMarkov(\n",
    "    timesteps, \n",
    "    naive_bayes=naive_bayes,\n",
    "    use_gazetteer=True,\n",
    "    use_features=True,\n",
    "    self_train=True\n",
    ")\n",
    "hmm.fit(X, Y)\n",
    " \n",
    "for name in ['train', 'valid', 'test']:\n",
    "    print('Predicting ' + name)\n",
    "    x, t, w = load_raw_dataset('data/' + name)\n",
    "    p = hmm.predict(x)\n",
    "    \n",
    "    t = [[['O', 'B-PER', 'I-PER'][t__] for t__ in t_] for t_ in t]\n",
    "    p = [[['O', 'B-PER', 'I-PER'][p__] for p__ in p_] for p_ in p]\n",
    "\n",
    "    with Path('{}.preds.txt'.format(name)).open('wb') as f:\n",
    "        for words, preds, tags in zip(w, p, t):\n",
    "            f.write(b'\\n')\n",
    "            for word, pred, tag in zip(words, preds, tags):\n",
    "                f.write(' '.join([word, tag, pred]).encode() + b'\\n')\n",
    "\n",
    "print('Elapsed time: %.4f' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 110269 tokens with 5822 phrases; found: 5991 phrases; correct: 5033.\n",
      "accuracy:  97.57%; precision:  84.01%; recall:  86.45%; FB1:  85.21\n",
      "              PER: precision:  84.01%; recall:  86.45%; FB1:  85.21  5991\n",
      "processed 36757 tokens with 1788 phrases; found: 2167 phrases; correct: 1619.\n",
      "accuracy:  96.36%; precision:  74.71%; recall:  90.55%; FB1:  81.87\n",
      "              PER: precision:  74.71%; recall:  90.55%; FB1:  81.87  2167\n",
      "processed 44795 tokens with 2723 phrases; found: 2725 phrases; correct: 2360.\n",
      "accuracy:  96.50%; precision:  86.61%; recall:  86.67%; FB1:  86.64\n",
      "              PER: precision:  86.61%; recall:  86.67%; FB1:  86.64  2725\n"
     ]
    }
   ],
   "source": [
    "! ./conlleval < train.preds.txt\n",
    "! ./conlleval < valid.preds.txt\n",
    "! ./conlleval < test.preds.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
