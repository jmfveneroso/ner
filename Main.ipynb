{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from models.estimator import Estimator\n",
    "from models.hmm import HiddenMarkov, load_raw_dataset\n",
    "\n",
    "# Disable Tensorflow's debug logs.\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Markov Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting train\n",
      "Predicting valid\n",
      "Predicting test\n",
      "Elapsed time: 24.5647\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "    \n",
    "X, Y, _ = load_raw_dataset('data/train')\n",
    "hmm = HiddenMarkov(\n",
    "    timesteps=1, \n",
    "    use_features=True,\n",
    "    self_train=True\n",
    ")\n",
    "hmm.fit(X, Y)\n",
    " \n",
    "# Write results.\n",
    "for name in ['train', 'valid', 'test']:\n",
    "    print('Predicting ' + name)\n",
    "    x, t, w = load_raw_dataset('data/' + name)\n",
    "    p = hmm.predict(x)\n",
    "    \n",
    "    t = [[['O', 'B-PER', 'I-PER'][t__] for t__ in t_] for t_ in t]\n",
    "    p = [[['O', 'B-PER', 'I-PER'][p__] for p__ in p_] for p_ in p]\n",
    "\n",
    "    Path('results').mkdir(parents=True, exist_ok=True)\n",
    "    with Path('results/{}.preds.txt'.format(name)).open('wb') as f:\n",
    "        for words, preds, tags in zip(w, p, t):\n",
    "            f.write(b'\\n')\n",
    "            for word, pred, tag in zip(words, preds, tags):\n",
    "                f.write(' '.join([word, tag, pred]).encode() + b'\\n')\n",
    "\n",
    "print('Elapsed time: %.4f' % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRF / Bi-LSTM-CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model...\n",
      "Loss: 0.0057, Acc: 1.0000, Time: 7.3136, Step: 300\n",
      "Loss: 0.0097, Acc: 1.0000, Time: 12.8564, Step: 600\n",
      "Loss: 0.0015, Acc: 1.0000, Time: 18.3857, Step: 900\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 29.4128, Step: 1200\n",
      "Loss: 0.0082, Acc: 1.0000, Time: 34.8828, Step: 1500\n",
      "Loss: 0.0042, Acc: 1.0000, Time: 41.3882, Step: 1800\n",
      "Loss: 0.0014, Acc: 1.0000, Time: 47.0916, Step: 2100\n",
      "Loss: 0.0017, Acc: 1.0000, Time: 52.3027, Step: 2400\n",
      "Loss: 0.0095, Acc: 1.0000, Time: 53.8915, Step: 2474\n",
      "train - Epoch 0, Precision: 0.9676, Recall: 0.9902, F1: 0.9788\n",
      "Loss: 0.0046, Acc: 1.0000, Time: 8.2811, Step: 300\n",
      "Loss: 0.0770, Acc: 1.0000, Time: 15.8911, Step: 600\n",
      "Loss: 0.0000, Acc: 1.0000, Time: 22.7086, Step: 876\n",
      "valid - Epoch 0, Precision: 0.8734, Recall: 0.9569, F1: 0.9133\n",
      "Loss: 1.0898, Acc: 0.9667, Time: 7.6243, Step: 300\n",
      "Loss: 0.0327, Acc: 1.0000, Time: 13.3096, Step: 600\n",
      "Loss: 0.1234, Acc: 0.9933, Time: 19.8172, Step: 900\n",
      "Loss: 0.0050, Acc: 1.0000, Time: 22.1869, Step: 1041\n",
      "test - Epoch 0, Precision: 0.8776, Recall: 0.8792, F1: 0.8784\n"
     ]
    }
   ],
   "source": [
    "estimator = Estimator()\n",
    "estimator.set_params({\n",
    "  'model': 'bi_lstm_crf', # bi_lstm_crf, crf\n",
    "  'char_representation': 'cnn',\n",
    "  'use_features': False,\n",
    "})\n",
    "estimator.train()\n",
    "estimator.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results\n",
    "\n",
    "With conlleval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed 110269 tokens with 5822 phrases; found: 5958 phrases; correct: 5765.\n",
      "accuracy:  99.58%; precision:  96.76%; recall:  99.02%; FB1:  97.88\n",
      "              PER: precision:  96.76%; recall:  99.02%; FB1:  97.88  5958\n",
      "processed 36757 tokens with 1788 phrases; found: 1959 phrases; correct: 1711.\n",
      "accuracy:  98.80%; precision:  87.34%; recall:  95.69%; FB1:  91.33\n",
      "              PER: precision:  87.34%; recall:  95.69%; FB1:  91.33  1959\n",
      "processed 44795 tokens with 2723 phrases; found: 2728 phrases; correct: 2394.\n",
      "accuracy:  98.12%; precision:  87.76%; recall:  87.92%; FB1:  87.84\n",
      "              PER: precision:  87.76%; recall:  87.92%; FB1:  87.84  2728\n"
     ]
    }
   ],
   "source": [
    "! ./conlleval < results/train.preds.txt\n",
    "! ./conlleval < results/valid.preds.txt\n",
    "! ./conlleval < results/test.preds.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
